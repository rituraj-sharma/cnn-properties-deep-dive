{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "24d7cda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from torch.nn import Sequential\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ad93de2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic_transform = transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Resize((224,224))\n",
    "# ])\n",
    "\n",
    "# temp_train_dataset = datasets.OxfordIIITPet(root='./dataF',split='trainval',target_types='category',transform=basic_transform,download=True)\n",
    "\n",
    "# loader = DataLoader(dataset=temp_train_dataset,batch_size=64,shuffle=False,num_workers=2)\n",
    "\n",
    "# mean,std = 0.0,0.0\n",
    "# total_number_samples = 0\n",
    "\n",
    "# for img,_ in tqdm(loader):\n",
    "#     batch_size = img.size(0)\n",
    "#     img = img.view(batch_size,img.size(1),-1)\n",
    "#     mean = img.mean(2).sum(0)\n",
    "#     std = img.std(2).sum(0)\n",
    "#     total_number_samples += batch_size\n",
    "\n",
    "# mean /= total_number_samples\n",
    "# std /= total_number_samples\n",
    "\n",
    "# print(\"Mean:\", mean)\n",
    "# print(\"std:\", std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9f136edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    # transforms.RandomHorizontalFlip(p=0.5),\n",
    "    # transforms.RandomCrop(224,padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_dataset = datasets.OxfordIIITPet(root='./dataF',split='trainval',target_types='category',transform=train_transform,download=True)\n",
    "test_dataset = datasets.OxfordIIITPet(root='./dataF',split='test',target_types='category',transform=test_transform,download=True)\n",
    "\n",
    "train_loader = DataLoader(train_dataset,batch_size=64,shuffle=True,num_workers=2)\n",
    "test_loader = DataLoader(test_dataset,batch_size=64,shuffle=False,num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0296a6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shwetank/Desktop/ShwetankAssignmentMT2025725/venv/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/shwetank/Desktop/ShwetankAssignmentMT2025725/venv/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "alexNet = models.alexnet(pretrained=True).to(device)\n",
    "for param in alexNet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "feature_extractor = Sequential(*list(alexNet.classifier.children())[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9b9ff375",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58/58 [00:12<00:00,  4.66it/s]\n",
      "100%|██████████| 58/58 [00:12<00:00,  4.63it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.2064,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 3.0781, 0.0000, 0.0000],\n",
       "        ...,\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_feature(loader):\n",
    "    features,labels = [],[]\n",
    "    alexNet.eval()\n",
    "    with torch.no_grad():\n",
    "        for imgs,lbls in tqdm(loader):\n",
    "            imgs = imgs.to(device)\n",
    "            x = alexNet.features(imgs)\n",
    "            x = alexNet.avgpool(x)\n",
    "            x = torch.flatten(x,1)\n",
    "            x = feature_extractor(x)\n",
    "            features.append(x.cpu())\n",
    "            labels.append(lbls.cpu())\n",
    "        return torch.cat(features),torch.cat(labels)\n",
    "    \n",
    "X_train, y_train = extract_feature(train_loader)\n",
    "X_test, y_test = extract_feature(test_loader)\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dc4a80d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.7454347233578632\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.numpy()\n",
    "y_train = y_train.numpy()\n",
    "X_test = X_test.numpy()\n",
    "y_test = y_test.numpy()\n",
    "\n",
    "##Logistic Regression##\n",
    "clf_logreg = LogisticRegression(max_iter=1000)\n",
    "clf_logreg.fit(X_train,y_train)\n",
    "pred_logreg = clf_logreg.predict(X_test)\n",
    "acc_logreg = accuracy_score(y_test, pred_logreg)\n",
    "print(\"Logistic Regression Accuracy:\", acc_logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bb67c2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.7239029708367403\n"
     ]
    }
   ],
   "source": [
    "clf_rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf_rf.fit(X_train, y_train)\n",
    "pred_rf = clf_rf.predict(X_test)\n",
    "acc_rf = accuracy_score(y_test, pred_rf)\n",
    "print(\"Random Forest Accuracy:\", acc_rf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
